{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8284b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from math import radians, degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8b74dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7ed6b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fda1d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_DIR = \"C:\\\\cv_project\\\\data\\\\Videos\"\n",
    "OUTPUT_DIR = \"output_csv\"\n",
    "FEATURE_COLS = [\n",
    "    \"Pitch\", \"Yaw\", \"Roll\", \"inBrL\", \"otBrL\", \"inBrR\", \"otBrR\",\n",
    "    \"EyeOL\", \"EyeOR\", \"oLipH\", \"iLipH\", \"LipCDt\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db71ef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_to_np(shape, dtype = 'double'):\n",
    "    coords = np.zeros((68, 2), dtype=dtype)\n",
    "    for i in range(68):\n",
    "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83480463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_face(frame):\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    faces = face_detector(rgb, 1)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        return np.zeros((68, 2))\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    shape = shape_predictor(gray, faces[0])\n",
    "    coords = shape_to_np(shape)\n",
    "\n",
    "    return coords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041bdb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),\n",
    "    (0.0, -70.0, -20.0),\n",
    "    (-35.0, 50.0, -20.0),\n",
    "    (35.0, 50.0, -20.0),\n",
    "    (-35.0, -50.0, -20.0),\n",
    "    (35.0, -50.0, -20.0),\n",
    "])\n",
    "\n",
    "def get_2d_points_from_landmarks(landmarks):\n",
    "    \"\"\"\n",
    "    Extracts 2D image points from the landmarks numpy array.\n",
    "    This assumes you have the landmarks as a numpy array of tuples (x, y).\n",
    "    \"\"\"\n",
    "    return np.array([\n",
    "        (landmarks[30][0], landmarks[30][1]),  # Nose tip\n",
    "        (landmarks[8][0], landmarks[8][1]),    # Chin\n",
    "        (landmarks[36][0], landmarks[36][1]),  # Left eye\n",
    "        (landmarks[45][0], landmarks[45][1]),  # Right eye\n",
    "        (landmarks[48][0], landmarks[48][1]),  # Left mouth corner\n",
    "        (landmarks[54][0], landmarks[54][1])   # Right mouth corner\n",
    "    ], dtype=\"double\")\n",
    "\n",
    "def get_pose_angles(rvec, tvec):\n",
    "    \"\"\"\n",
    "    Convert rotation vector to pitch, yaw, and roll.\n",
    "    \"\"\"\n",
    "    R, _ = cv2.Rodrigues(rvec)\n",
    "\n",
    "    pitch = np.arctan2(R[2, 1], R[2, 2])  # pitch (rotation around X-axis)\n",
    "    yaw = np.arctan2(-R[2, 0], np.sqrt(R[2, 1]**2 + R[2, 2]**2))  # yaw (rotation around Y-axis)\n",
    "    roll = np.arctan2(R[1, 0], R[0, 0])  # roll (rotation around Z-axis)\n",
    "\n",
    "    # Convert to degrees\n",
    "    return degrees(pitch), degrees(yaw), degrees(roll)\n",
    "\n",
    "def calculate_pose(landmarks, frame):\n",
    "    \"\"\"\n",
    "    Given a set of landmarks and the frame, estimate the pitch, yaw, and roll of the face.\n",
    "    \"\"\"\n",
    "    # 2D points from the landmarks array\n",
    "    image_points = get_2d_points_from_landmarks(landmarks)\n",
    "\n",
    "    # Camera matrix (assumed focal length and image center based on input size)\n",
    "    size = frame.shape\n",
    "    focal_length = size[1]  # Width of the image\n",
    "    center = (size[1] / 2, size[0] / 2)  # Image center\n",
    "\n",
    "    camera_matrix = np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=\"double\")\n",
    "\n",
    "    dist_coeffs = np.zeros((4, 1))  # Assuming no lens distortion\n",
    "\n",
    "    # Solve for rotation and translation vectors\n",
    "    _, rvec, tvec = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs)\n",
    "\n",
    "    # Get pitch, yaw, roll from rotation vector\n",
    "    pitch, yaw, roll = get_pose_angles(rvec, tvec)\n",
    "\n",
    "    return pitch, yaw, roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ed7597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_frame(frame):\n",
    "\n",
    "    #Extract landmarks for given frame\n",
    "    landmarks = preprocess_face(frame)\n",
    "\n",
    "    if landmarks is None:\n",
    "        return np.zeros(len(FEATURE_COLS))\n",
    "\n",
    "    # Compute Facial Features\n",
    "    #-> Head Movement Features\n",
    "\n",
    "    pitch, yaw, roll = calculate_pose(landmarks, frame)\n",
    "\n",
    "    # -> Eyebrow Features\n",
    "    inBrL = np.linalg.norm(landmarks[22] - landmarks[42])\n",
    "    otBrL = np.linalg.norm(landmarks[26] - landmarks[45])\n",
    "    inBrR = np.linalg.norm(landmarks[17] - landmarks[39])\n",
    "    otBrR = np.linalg.norm(landmarks[21] - landmarks[36])\n",
    "    EyeOL = np.linalg.norm(landmarks[36] - landmarks[39])\n",
    "    EyeOR = np.linalg.norm(landmarks[42] - landmarks[45])\n",
    "\n",
    "    # -> Lip features\n",
    "    oLipH = np.abs(landmarks[51][1] - landmarks[57][1])\n",
    "    iLipH = np.abs(landmarks[62][1] - landmarks[66][1])\n",
    "    LipCDt = np.linalg.norm(landmarks[48] - landmarks[54])\n",
    "\n",
    "\n",
    "    return np.array([\n",
    "        pitch, yaw, roll, inBrL, otBrL, inBrR, otBrR, EyeOL, EyeOR, oLipH, iLipH, LipCDt\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0702598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path):\n",
    "    print(f\"Processing {video_path.name}...\")\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    features = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Resize or preprocess frame if needed\n",
    "        frame_features = extract_features_from_frame(frame)\n",
    "        features.append(frame_features)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(features) == 0:\n",
    "        print(f\"Warning: No frames extracted for {video_path.name}\")\n",
    "        return\n",
    "\n",
    "    features = np.array(features)\n",
    "    # features_norm = normalize_features(features)\n",
    "\n",
    "    df = pd.DataFrame(features, columns=FEATURE_COLS)\n",
    "    output_path = Path(OUTPUT_DIR) / f\"{video_path.stem}_raw.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved CSV: {output_path.name}\")\n",
    "\n",
    "def process_all_videos():\n",
    "    video_files = list(Path(VIDEO_DIR).glob(\"*.avi\"))\n",
    "    for video_path in video_files:\n",
    "        process_video(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387f6cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_all_videos()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
