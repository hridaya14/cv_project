{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T19:57:13.674485Z",
     "iopub.status.busy": "2025-04-20T19:57:13.673718Z",
     "iopub.status.idle": "2025-04-20T19:57:26.356869Z",
     "shell.execute_reply": "2025-04-20T19:57:26.356070Z",
     "shell.execute_reply.started": "2025-04-20T19:57:13.674455Z"
    },
    "id": "kB-FflSX_KfS",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from math import radians, degrees\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T19:11:19.251001Z",
     "iopub.status.busy": "2025-04-20T19:11:19.250474Z",
     "iopub.status.idle": "2025-04-20T19:11:19.254529Z",
     "shell.execute_reply": "2025-04-20T19:11:19.253740Z",
     "shell.execute_reply.started": "2025-04-20T19:11:19.250978Z"
    },
    "id": "7deOQGAUGhXA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- CONFIG ---\n",
    "VIDEO_DIR = \"C:\\\\cv_project\\\\data\\\\Videos\"\n",
    "OUTPUT_DIR = \"C:\\\\cv_project\\\\code\\\\output_csv\"\n",
    "FEATURE_COLS = [\n",
    "    \"Pitch\", \"Yaw\", \"Roll\", \"inBrL\", \"otBrL\", \"inBrR\", \"otBrR\",\n",
    "    \"EyeOL\", \"EyeOR\", \"oLipH\", \"iLipH\", \"LipCDt\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe.tasks.python import BaseOptions\n",
    "\n",
    "base_options = BaseOptions(model_asset_path='face_landmarker.task', delegate=\"CPU\")\n",
    "options = vision.FaceLandmarkerOptions(base_options=base_options,\n",
    "                                        output_face_blendshapes=True,\n",
    "                                        output_facial_transformation_matrixes=True,\n",
    "                                        num_faces=1)\n",
    "detector = vision.FaceLandmarker.create_from_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"C:\\\\cv_project\\\\data\\\\Videos\\\\P1.avi\")\n",
    "frames = []\n",
    "ret = True\n",
    "while ret:\n",
    "   ret, frame = cap.read()\n",
    "   if not ret:\n",
    "       break\n",
    "   frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "   frames.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx = 1700\n",
    "image = mp.Image(\n",
    "   image_format=mp.ImageFormat.SRGB, data=frames[frame_idx]\n",
    ")\n",
    "detection_result = detector.detect(image)\n",
    "frame_scores = np.array([blendshape.score for blendshape in detection_result.face_blendshapes[0]])\n",
    "blendshape_names = [blendshape.category_name for blendshape in detection_result.face_blendshapes[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_neutral',\n",
       " 'browDownLeft',\n",
       " 'browDownRight',\n",
       " 'browInnerUp',\n",
       " 'browOuterUpLeft',\n",
       " 'browOuterUpRight',\n",
       " 'cheekPuff',\n",
       " 'cheekSquintLeft',\n",
       " 'cheekSquintRight',\n",
       " 'eyeBlinkLeft',\n",
       " 'eyeBlinkRight',\n",
       " 'eyeLookDownLeft',\n",
       " 'eyeLookDownRight',\n",
       " 'eyeLookInLeft',\n",
       " 'eyeLookInRight',\n",
       " 'eyeLookOutLeft',\n",
       " 'eyeLookOutRight',\n",
       " 'eyeLookUpLeft',\n",
       " 'eyeLookUpRight',\n",
       " 'eyeSquintLeft',\n",
       " 'eyeSquintRight',\n",
       " 'eyeWideLeft',\n",
       " 'eyeWideRight',\n",
       " 'jawForward',\n",
       " 'jawLeft',\n",
       " 'jawOpen',\n",
       " 'jawRight',\n",
       " 'mouthClose',\n",
       " 'mouthDimpleLeft',\n",
       " 'mouthDimpleRight',\n",
       " 'mouthFrownLeft',\n",
       " 'mouthFrownRight',\n",
       " 'mouthFunnel',\n",
       " 'mouthLeft',\n",
       " 'mouthLowerDownLeft',\n",
       " 'mouthLowerDownRight',\n",
       " 'mouthPressLeft',\n",
       " 'mouthPressRight',\n",
       " 'mouthPucker',\n",
       " 'mouthRight',\n",
       " 'mouthRollLower',\n",
       " 'mouthRollUpper',\n",
       " 'mouthShrugLower',\n",
       " 'mouthShrugUpper',\n",
       " 'mouthSmileLeft',\n",
       " 'mouthSmileRight',\n",
       " 'mouthStretchLeft',\n",
       " 'mouthStretchRight',\n",
       " 'mouthUpperUpLeft',\n",
       " 'mouthUpperUpRight',\n",
       " 'noseSneerLeft',\n",
       " 'noseSneerRight']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blendshape_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtM2AfPgGiSg"
   },
   "source": [
    "## Facial Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def process_frames(frames, detector):\n",
    "    \"\"\"Process frames to calculate blendshape scores.\"\"\"\n",
    "    blendshape_sums = None\n",
    "    frame_count = 0\n",
    "    blendshape_names = []\n",
    "\n",
    "    for frame in frames:\n",
    "        image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "        detection_result = detector.detect(image)\n",
    "\n",
    "        # Skip frames without face_blendshapes\n",
    "        if not detection_result.face_blendshapes:\n",
    "            continue\n",
    "\n",
    "        frame_scores = np.array([blendshape.score for blendshape in detection_result.face_blendshapes[0]])\n",
    "        if blendshape_sums is None:\n",
    "            blendshape_sums = np.zeros_like(frame_scores)\n",
    "            blendshape_names = [blendshape.category_name for blendshape in detection_result.face_blendshapes[0]]\n",
    "        blendshape_sums += frame_scores\n",
    "        frame_count += 1\n",
    "\n",
    "    return blendshape_sums, frame_count, blendshape_names\n",
    "\n",
    "\n",
    "def calculate_average_blendshapes(blendshape_sums, frame_count, blendshape_names):\n",
    "    \"\"\"Calculate average blendshapes for a video.\"\"\"\n",
    "    if frame_count > 0:\n",
    "        blendshape_averages = blendshape_sums / frame_count\n",
    "        return dict(zip(blendshape_names, blendshape_averages))\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Labels\n",
    "\n",
    "def process_video(video_file, detector, output_dir):\n",
    "    \"\"\"Process a single video file.\"\"\"\n",
    "    print(f\"Processing video: {video_file.name}\")\n",
    "\n",
    "    # Open the video file and read frames\n",
    "    cap = cv2.VideoCapture(str(video_file))\n",
    "    frames = []\n",
    "    ret = True\n",
    "    while ret:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "\n",
    "    # Process frames and calculate blendshape averages\n",
    "    blendshape_sums, frame_count, blendshape_names = process_frames(frames, detector)\n",
    "    video_data = calculate_average_blendshapes(blendshape_sums, frame_count, blendshape_names)\n",
    "\n",
    "    if video_data:\n",
    "        # Ensure video name is the first column and columns are set using blendshape_names\n",
    "        video_data_row = {\"Video\": video_file.name}\n",
    "        video_data_row.update({name: video_data.get(name, 0) for name in blendshape_names})\n",
    "        return video_data_row\n",
    "    else:\n",
    "        print(f\"No face blendshapes detected in video: {video_file.name}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_results_to_csv(video_data, output_dir):\n",
    "    \"\"\"Save video data to a CSV file.\"\"\"\n",
    "    output_file = Path(output_dir) / \"results.csv\"\n",
    "    df = pd.DataFrame([video_data])\n",
    "    if not output_file.exists():\n",
    "        df.to_csv(output_file, index=False)\n",
    "    else:\n",
    "        df.to_csv(output_file, mode='a', header=False, index=False)\n",
    "\n",
    "\n",
    "def main(video_dir, output_dir, detector):\n",
    "    \"\"\"Main function to process all videos in the directory.\"\"\"\n",
    "    for video_file in sorted(Path(video_dir).glob(\"*.avi\")):  # Sort files alphabetically\n",
    "        video_data = process_video(video_file, detector, output_dir)\n",
    "        if video_data:\n",
    "            save_results_to_csv(video_data, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7202984,
     "sourceId": 11490836,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 311668,
     "modelInstanceId": 290979,
     "sourceId": 348442,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
